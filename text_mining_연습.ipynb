{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wSb8AI5BSa8v3bOsm1DT5D1-y2Q_8kl_",
      "authorship_tag": "ABX9TyPDgIgJVRrxoufgOIchYp39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gim4620/Python/blob/main/text_mining_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SfoEmaj9E_1",
        "outputId": "5f1755fb-8f97-466b-e504-c5660327fbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['안녕하세요.  a\\n', '여러분']\n"
          ]
        }
      ],
      "source": [
        "with open ('/content/test.txt', 'r') as f:\n",
        "    while True:\n",
        "        line = f.readlines() #readlines: 모든 lines을 읽어 달라; readline: 빈칸이 없는 lines을 읽어 달라\n",
        "        if not line: break\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('/content/test.txt', 'r') as f:\n",
        "    while True:\n",
        "        line = f.readline() #readlines: 모든 lines을 읽어 달라; readline: 빈칸이 없는 lines을 읽어 달라\n",
        "        if not line: break\n",
        "        print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqOdYypa9Xf6",
        "outputId": "89bde13b-3189-4744-e470-af38b9b4fb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요.  a\n",
            "\n",
            "여러분\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# d = pd.read_csv('a.excel')은 안 읽힘\n",
        "# e = pd.read_xlsx('a.excel')로 읽어야"
      ],
      "metadata": {
        "id": "eP_O4ZKS9nW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopword')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r16k9N1aCXwb",
        "outputId": "46d62916-16cc-44e4-ff3e-7798cf2a739d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading stopword: Package 'stopword' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "EeUkjZypDD4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "text = sent_tokenize(text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX-DAqgCDIMk",
        "outputId": "0e4944ed-b963-4ae4-d080-e4a81bfc92f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "vocab = {}\n",
        "sentences = []\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "for i in text:\n",
        "    sentence = word_tokenize(i)\n",
        "    result = []\n",
        "\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in stop_words:\n",
        "            if len(word) > 2:\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0\n",
        "                vocab[word] += 1\n",
        "    sentences.append(result)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_E4xHL1DJeJ",
        "outputId": "0e69975e-2e0f-4e69-ed2d-05bc17f4ce69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v67ekThsEKIB",
        "outputId": "e21dc53f-3576-4761-fd08-b07231ea1563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 8,\n",
              " 'person': 3,\n",
              " 'good': 1,\n",
              " 'huge': 5,\n",
              " 'knew': 1,\n",
              " 'secret': 6,\n",
              " 'kept': 4,\n",
              " 'word': 2,\n",
              " 'keeping': 2,\n",
              " 'driving': 1,\n",
              " 'crazy': 1,\n",
              " 'went': 1,\n",
              " 'mountain': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lambda: 한 줄을 실행한 결과 값이 바로 반환 값이 됨"
      ],
      "metadata": {
        "id": "NIC8K624Lieq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plus_two(num):\n",
        "    return num + 2\n",
        "\n",
        "a = 2\n",
        "b = plus_two(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6rxTP4QE-1-",
        "outputId": "f9b23b13-3cd5-43f1-ecfa-ecdc6e22559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func2 = lambda x:x+2\n",
        "func2(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9kQF0dILx4b",
        "outputId": "785c42c0-a1ae-46da-a482-93b51a7e960b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# map 함수: 리스트, 튜플, 스프링 등 자료형 각각의 원소에 동일한 함수 적용\n",
        "\n",
        "map(함수, 자료형)"
      ],
      "metadata": {
        "id": "38UWwH82L5wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items = [1, 2, 3, 4, 5]\n",
        "squared_map = list(map(lambda x:x**2, items)) # list() 안쓰면 함수로만 보여줌\n",
        "print(squared_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j08NTWvJL3rf",
        "outputId": "e14dfa20-9fb8-4503-e1ee-869cdb0fbe27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squared = []\n",
        "for i in items:\n",
        "    squared.append(i*i)\n",
        "\n",
        "print(squared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya-EyK0GMZIx",
        "outputId": "b8d56fbd-f84f-4487-f80a-b5d7c4b63164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[\"barber\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zolN9eBxMgwc",
        "outputId": "8b800782-c7ef-485b-c284-dbe064727fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngSUf3dAND0Q",
        "outputId": "5fd37664-d671-45de-a850-7d77064ac180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab_sorted:\n",
        "    if frequency > 1: #빈도수가 적은 단어는 제외한다.\n",
        "        i=i+1\n",
        "        word_to_index[word]=i\n",
        "print(word_to_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bqTz_qSNU5v",
        "outputId": "8011565d-ffba-4e2d-d4b6-3fea6c5a180e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
        "for w in words_frequency:\n",
        "    del word_to_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVa_AEA0NyLb",
        "outputId": "2b0abd0d-ba6c-430b-d7db-a37ab707ceac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1"
      ],
      "metadata": {
        "id": "1YtkFSGdPXlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩\n",
        "\n",
        "encoded = []\n",
        "for s in sentences:\n",
        "    temp = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            temp.append(word_to_index[w])\n",
        "        except KeyError:\n",
        "            temp.append(word_to_index['OOV'])\n",
        "    encoded.append(temp)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB7Aa9PEPZTq",
        "outputId": "c461626e-3ba1-4c19-d822-e104ae13b31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "EQN64fefPai0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_pGXCsaQWoA",
        "outputId": "8d8a850a-fa3c-4aa5-e4b3-10f31362beb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합(Vocabulary)을 만들기 위해서\n",
        "#sentences에서 문장의 경계인 [,]를 제거하고 단어들을 하나의 리스트로 만듬\n",
        "words = sum(sentences, [])\n",
        "# 위 작업은 words = np.hstack(sentences)로도 수행 가능.\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3r_QCYFQXns",
        "outputId": "6e82f00d-a2df-4688-e577-b7046dce2a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter(words)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIw__AzBQ3i5",
        "outputId": "d8993b31-dfc1-49e5-b8fb-fd407b08b30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[\"barber\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVActd_9Q53a",
        "outputId": "1241ab5c-e3f1-47fb-9ff4-031083236c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd9ASq9cQ60_",
        "outputId": "eeab60b1-a79f-4ea8-ac3f-4da6112c5845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = [[4, 5, 6], [7, 8, 9]]\n"
      ],
      "metadata": {
        "id": "VGH3ZlbnRciM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6_z4prAsbuLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['barber', 'barber', 'person', 'barber', 'good', 'person']"
      ],
      "metadata": {
        "id": "8yxqZjCjbx6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = FreqDist(np.hstack(sentences))\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeFlFfHKb37P",
        "outputId": "23486e8f-acc3-4409-c308-67be38d73110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'barber': 3, 'person': 2, 'good': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack(sentences) # array로 쌓아진 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eWhrAjxb8Ix",
        "outputId": "e45a0dd7-dbc1-4fa4-dde1-d21fd2e53980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['barber', 'barber', 'person', 'barber', 'good', 'person'],\n",
              "      dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "XTaOkHzhcMwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe88fbf-3cb2-467e-8df7-82815837f966"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYCRuYuj4Etz",
        "outputId": "8f396460-8ea6-4546-896c-bad673e77e79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(\"I like you. You're my son\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWuNGbmb4MXr",
        "outputId": "a6151ff6-5862-4726-cb4b-8f77120e5375"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I like you.', \"You're my son\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWmPcosA4tw9",
        "outputId": "22ade8b6-813b-4fa9-a46d-7a618a44ea1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"David\\'s book wasn\\'t famous, but his family loved his book.\"\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVXhnXnO5L1W",
        "outputId": "86962a73-261a-4c48-d5da-d27b996999ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['David',\n",
              " \"'s\",\n",
              " 'book',\n",
              " 'was',\n",
              " \"n't\",\n",
              " 'famous',\n",
              " ',',\n",
              " 'but',\n",
              " 'his',\n",
              " 'family',\n",
              " 'loved',\n",
              " 'his',\n",
              " 'book',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "r = input(\"Pleas write a text: \")\n",
        "print(\"The length of text is\", len(word_tokenize(r)), \"words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNJKc6gP5bDB",
        "outputId": "831f7138-657c-480d-89a2-4cbcd4043917"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pleas write a text: I love banana\n",
            "The length of text is 3 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "r = input(\"Please write a text: \")\n",
        "print(\"The length of text is,\", len(word_tokenize(r)), \"words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thi6UvmJ536F",
        "outputId": "bf805817-b4ef-4a44-be63-eca4e3f98bb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please write a text: Do you have any questions?\n",
            "The length of text is, 6 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"I love banana. and you?\"\n",
        "r = word_tokenize(sentence)\n",
        "\n",
        "print(type(r), len(r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipyjd2Gr6OT-",
        "outputId": "76a432a5-a54a-4684-f780-db7c44e0a595"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "sentence = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "word = WordPunctTokenizer().tokenize(sentence)\n",
        "# word(sentence)\n",
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_8gYVGF7BpW",
        "outputId": "7ff7f02f-39a1-4487-a0f0-967146d40170"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Don',\n",
              " \"'\",\n",
              " 't',\n",
              " 'be',\n",
              " 'fooled',\n",
              " 'by',\n",
              " 'the',\n",
              " 'dark',\n",
              " 'sounding',\n",
              " 'name',\n",
              " ',',\n",
              " 'Mr',\n",
              " '.',\n",
              " 'Jone',\n",
              " \"'\",\n",
              " 's',\n",
              " 'Orphanage',\n",
              " 'is',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'goes',\n",
              " 'for',\n",
              " 'a',\n",
              " 'pastry',\n",
              " 'shop',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "sentence = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "\n",
        "word = WordPunctTokenizer().tokenize(sentence)\n",
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxpEFSXQAfT4",
        "outputId": "ac1b90ea-61ec-4dee-dc1e-4f3217bc461c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Don',\n",
              " \"'\",\n",
              " 't',\n",
              " 'be',\n",
              " 'fooled',\n",
              " 'by',\n",
              " 'the',\n",
              " 'dark',\n",
              " 'sounding',\n",
              " 'name',\n",
              " ',',\n",
              " 'Mr',\n",
              " '.',\n",
              " 'Jone',\n",
              " \"'\",\n",
              " 's',\n",
              " 'Orphanage',\n",
              " 'is',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'goes',\n",
              " 'for',\n",
              " 'a',\n",
              " 'pastry',\n",
              " 'shop',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "print(tokenizer.tokenize('I love banana. You are a boy'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdaH50L4B06P",
        "outputId": "a1389781-0ee6-446d-ea97-7012c6aa810f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'banana', '.', 'You', 'are', 'a', 'boy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "sentence = \"There is no royal road to learning\"\n",
        "bigram = list(ngrams(sentence.split(), 2))\n",
        "print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjycFnx0D9XE",
        "outputId": "292a27a7-e841-4184-965e-67bfb2d1213f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'is'), ('is', 'no'), ('no', 'royal'), ('royal', 'road'), ('road', 'to'), ('to', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram = ngrams(sentence.split(), 3)\n",
        "list(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhLUcwFaE-FD",
        "outputId": "d5d1ae54-b6c5-4428-d908-c7778ddc6de2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('There', 'is', 'no'),\n",
              " ('is', 'no', 'royal'),\n",
              " ('no', 'royal', 'road'),\n",
              " ('royal', 'road', 'to'),\n",
              " ('road', 'to', 'learning')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams(text, n):\n",
        "    \"\"\"\n",
        "    takes tokens or text, returns a list of n-grams\n",
        "    \"\"\"\n",
        "    return [text[i:i+n] for i in range(len(text)-n+1)]\n",
        "\n",
        "    cleaned = [\"mary\",\",\",\"n't\",\"slap\",\"green\",'witch',\".\"]\n",
        "print(n_grams(cleaned,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "ykrLgCn5GOvD",
        "outputId": "d551db90-ceb3-447f-aff4-858d2a1cf513"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cleaned' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e202892eb122>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mary\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"n't\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"slap\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'witch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_grams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cleaned' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print('영어 불용어 갯수:', len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NrR_Vk7Ge1X",
        "outputId": "7de6d23e-6e0a-4beb-a4cc-c676cf8120b0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 불용어 갯수: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print(\"영어불용어 갯수:\", len(nltk.corpus.stopwords.words('english')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pomXvZvBIqZc",
        "outputId": "75be21be-51e0-4365-bc02-72852e3ea2c5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어불용어 갯수: 179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print('영어불용어 갯수:', len(nltk.corpus.stopwords.words('english')))\n",
        "print('영어불용어 상위 40개:', nltk.corpus.stopwords.words('english')[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPSlVqnJJV56",
        "outputId": "f413216e-d585-44f3-fc50-6751e0d98b28"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어불용어 갯수: 179\n",
            "영어불용어 상위 40개: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "6zPwL95mN956"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd #현재 경로 -> nsmc-mater -> 상대경로로 접근해보세요."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8agN9cFcPrTY",
        "outputId": "93eb634f-cf56-4c33-82d9-822990b89bc8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyTfOq0CPwwU",
        "outputId": "17360e35-f7bf-4c19-8c87-75b111470754"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb_nShSNPyzl",
        "outputId": "96334ed1-12be-471f-9015-aaf1cedfc169"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './content'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nt9n2ZQ1P3AK",
        "outputId": "9d5f8c02-ea35-4fb3-aa40-a0a8f98cff73"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/알파코 딥러닝 부트 캠프/오프라인/2. 데이터 전처리 및 Text Mining (20240321-/데이터/nsmc-master'\n",
        "\n"
      ],
      "metadata": {
        "id": "yvrS02oGMyGH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stopword = set(stopwords.words('english'))\n",
        "\n",
        "word_token = word_tokenize(example)\n",
        "\n",
        "result = []\n",
        "for i in word_token:\n",
        "    if i not in stopword:\n",
        "        result.append(i)\n",
        "\n",
        "print(word_token)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWoYlEfkO7OF",
        "outputId": "e41cbb4d-d1ab-43f8-ce07-953c436e5b75"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming\"\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "results = []\n",
        "\n",
        "for token in word_tokenize(text):\n",
        "    if token not in stopwords:\n",
        "        results.append(token)\n",
        "\n",
        "print(word_tokenize(text), '\\n')\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaVlp5mWN6Kh",
        "outputId": "8958d5d3-0957-449d-f1f1-ef43f4db5125"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Natural', 'Language', 'Toolkit', ',', 'or', 'more', 'commonly', 'NLTK', ',', 'is', 'a', 'suite', 'of', 'libraries', 'and', 'programs', 'for', 'symbolic', 'and', 'statistical', 'natural', 'language', 'processing', 'for', 'English', 'written', 'in', 'the', 'Python', 'programming'] \n",
            "\n",
            "['The', 'Natural', 'Language', 'Toolkit', ',', 'commonly', 'NLTK', ',', 'suite', 'libraries', 'programs', 'symbolic', 'statistical', 'natural', 'language', 'processing', 'English', 'written', 'Python', 'programming']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = \"on in the\"\n",
        "stop_words = stop_words.split(\" \")\n",
        "stop_words\n",
        "\n",
        "sentence = \"singer on the stage\"\n",
        "sentence = sentence.split()\n",
        "\n",
        "nouns = []\n",
        "for token in sentence:\n",
        "    if token not in stop_words:\n",
        "        nouns.append(token)\n",
        "\n",
        "print(nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ukZwI5SdEk",
        "outputId": "0adae18d-3c67-46d4-fcca-1079f865de3e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['singer', 'stage']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
        "\n",
        "shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('', text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48YMyUlBSoAc",
        "outputId": "2022c982-4769-41fd-caff-6780c139c986"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " was wondering anyone out there could enlighten this car.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(u\"he was running late\")\n",
        "\n",
        "for token in doc:\n",
        "    print('{} -> {}'.format(token, token.lemma_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzmWAHoFWAj7",
        "outputId": "2e1546ed-ada2-4287-a9b6-2a813a89805e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he -> he\n",
            "was -> be\n",
            "running -> run\n",
            "late -> late\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(stemmer.stem('Works'), stemmer.stem('Worked'), stemmer.stem('Working'))\n",
        "print(stemmer.stem('happier'), stemmer.stem('happiest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJohugJpWb3S",
        "outputId": "c66359eb-4816-4d35-c77d-948293841eb4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "happier happiest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem(\"happier\"), stemmer.stem('happies'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta8mp_4mahSp",
        "outputId": "32477401-0104-4b9e-be09-c2e7427bae05"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "korean_words = [\"가다\", \"갔다\", \"가고\", \"가시다\", \"가시어\", \"가시어요\"]\n",
        "\n",
        "for word in korean_words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Original word: {word}, stemmed word: {stemmed_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbxDu3kua-y2",
        "outputId": "4ca7410d-4cda-4a0a-be66-fba30faed123"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original word: 가다, stemmed word: 가다\n",
            "Original word: 갔다, stemmed word: 갔다\n",
            "Original word: 가고, stemmed word: 가고\n",
            "Original word: 가시다, stemmed word: 가시다\n",
            "Original word: 가시어, stemmed word: 가시어\n",
            "Original word: 가시어요, stemmed word: 가시어요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['formalize', 'allowance', 'electrical']\n",
        "print([stemmer.stem(w) for w in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAZ-b6Y2brB6",
        "outputId": "d30abf5b-f3a1-48c6-d523-7299aab00c94"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['formal', 'allow', 'electr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUoSz-Cab7LX",
        "outputId": "3e719998-0c88-4539-b5b6-22c0c5c8fea4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def porter_stemmer(token_list):\n",
        "    p = PorterStemmer()\n",
        "    result = []\n",
        "\n",
        "    for w in word_tokenize(token_list):\n",
        "        result.append(p.stem(w))\n",
        "\n",
        "    return result\n",
        "\n",
        "def lancaster_stemmer(token_list):\n",
        "    l = LancasterStemmer()\n",
        "    result = []\n",
        "\n",
        "    for w in word_tokenize(w):\n",
        "        result.append(l.stem(w))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "1VjXZE-bcrCi"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare(origin, compare):\n",
        "\n",
        "    result = []\n",
        "    for i in range(len(origin)):\n",
        "        if str(origin[i]) == str(compare[i]):\n",
        "            pass\n",
        "        else:\n",
        "            result.append(compare[i])\n",
        "    print('\\033[1m' + str(result) + '\\033[0m')"
      ],
      "metadata": {
        "id": "-cOFgpRvdqBy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "print(lemma.lemmatize('amusing'), lemma.lemmatize('amuses'), lemma.lemmatize('amused'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhuR1nFNdvH2",
        "outputId": "6daf7c0c-8fbc-4044-9ba3-a79adceb72e7"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amusing amuses amused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemma.lemmatize('amusing', 'v'), lemma.lemmatize('amuses', 'v'), lemma.lemmatize('amused', 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCka_TEGfioM",
        "outputId": "d10e037e-cceb-4129-da7f-61887e5e7c04"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r = re.compile(\"a.c\")\n",
        "\n",
        "r.search('axc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6hjm4qsfzPL",
        "outputId": "6f30b9f8-af21-4426-ecfd-765be88939dd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='axc'>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile('ab?c')\n",
        "\n",
        "print(r.search('abc'))\n",
        "print(r.search('abbc'))\n",
        "print(r.search('ac'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRb0jIS9gS6r",
        "outputId": "56d1789d-f54d-457a-9695-ca7b76ceede7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 3), match='abc'>\n",
            "None\n",
            "<re.Match object; span=(0, 2), match='ac'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab*c\")\n",
        "\n",
        "print(r.search(\"abbbbbbc\"))\n",
        "print(r.search(\"ac\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQpOFQiagzkb",
        "outputId": "f087b342-f317-4703-df1b-d06b4a7c3a90"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 8), match='abbbbbbc'>\n",
            "<re.Match object; span=(0, 2), match='ac'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab+c\")\n",
        "\n",
        "print(r.search(\"ac\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_BqK4wug_Qg",
        "outputId": "94a1464c-aed5-43ed-d4b5-7f5f9f3b3309"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"^a\")\n",
        "\n",
        "print(r.search(\"abbb\"))\n",
        "print(r.search(\"apple\"))\n",
        "print(r.search(\"banana\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGNHxNlAhJG-",
        "outputId": "13b6a228-9684-48f6-83a2-00ee7ab367e7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='a'>\n",
            "<re.Match object; span=(0, 1), match='a'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2}c\")\n",
        "\n",
        "print(r.search('abc'))\n",
        "print(r.search('abbc'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oku66d3dhu2Z",
        "outputId": "4b76c289-4b0d-47a7-ab3a-66be3539ba06"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "<re.Match object; span=(0, 4), match='abbc'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{2,8}c\")\n",
        "\n",
        "print(r.search(\"abc\"))\n",
        "print(r.search(\"abbc\"))\n",
        "print(r.search(\"abbbbbbbbc\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oejpcQHCjYma",
        "outputId": "5903154e-e242-466d-a71e-fb1f9116d15d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "<re.Match object; span=(0, 4), match='abbc'>\n",
            "<re.Match object; span=(0, 10), match='abbbbbbbbc'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[abc]\")\n",
        "\n",
        "print(r.search('ab'))\n",
        "print(r.search('ef'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXSlLPmPjpEx",
        "outputId": "563cae88-6099-42d3-8a8c-8157eb748f08"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='a'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[a-c]\")\n",
        "\n",
        "r.search('copy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtsaASkNkJkp",
        "outputId": "3e761d9b-743b-43db-9081-1bc32950eb3d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='c'>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search('match')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmg_6BzdkPrQ",
        "outputId": "4ba10134-6692-4630-d8a9-5632c901b894"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(1, 2), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[0-5]\")\n",
        "\n",
        "r.search('korea1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfzu3T11kRXk",
        "outputId": "8ee94bc0-2709-4d3e-c3d7-8a84aa679d03"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(5, 6), match='1'>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[a-zA-Z]\")\n",
        "\n",
        "r.search(\"traing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ6RwCGekZP9",
        "outputId": "573883ff-a7c3-43cc-aed6-37f712838639"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='t'>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[0-9]\")\n",
        "\n",
        "r.search(\"aaa0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tboWSypXkqFZ",
        "outputId": "1c14670c-e4d0-440e-bb8d-9d727c29bb60"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(3, 4), match='0'>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " r = re.compile(\"[^abc]\")\n",
        "\n",
        " r.search('edf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugFGa3phk35H",
        "outputId": "a0733ba7-d60e-4901-c3ae-d94ccb352125"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='e'>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search('a')"
      ],
      "metadata": {
        "id": "TclRnPUMlZ8P"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab.\")\n",
        "\n",
        "r.search(\"kkabc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHf8W06AlbtJ",
        "outputId": "c43301d9-afd7-453d-e03a-30ac15b32018"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(2, 5), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"kkabcc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8AV_zRjnCUT",
        "outputId": "80b3a799-da12-46ec-d6b3-61e5d6903a2f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(2, 5), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abdkk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okYopZ5hnFJ-",
        "outputId": "386ab82c-8824-4100-aee4-48cd0703339e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abd'>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.match(\"abckk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyLictV7nOmR",
        "outputId": "4ded5b90-fffe-490a-8975-3146a49dcae5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"사과 딸기 수박 멜론 바나나\"\n",
        "re.split(\" \", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvAm570bnRqk",
        "outputId": "f57c16de-abf3-4873-bc51-f7d771383e63"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '멜론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"사과\n",
        "딸기\n",
        "수박\n",
        "멜론\n",
        "바나나\"\"\"\n",
        "\n",
        "re.split(\"\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5oXwu7annpI",
        "outputId": "cd57a9da-58f4-43bf-e7e1-f653cbeb8252"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '멜론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"바나나와 딸기\n",
        "초코와 쿠키\"\"\"\n",
        "\n",
        "re.split(\"\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjceXyu7nv7x",
        "outputId": "02383ef2-9fc8-4fde-af17-daec37188898"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['바나나와 딸기', '초코와 쿠키']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"사과+딸기+수박+멜론+바나나\"\n",
        "\n",
        "re.split(\"\\+\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQhcT3pqn6Jl",
        "outputId": "96c590b8-ec37-4165-e37f-a57d253ef9d1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '멜론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.split('+')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0sQaZxhp6uy",
        "outputId": "11b059a9-4053-4983-8b54-62a64aaf3bac"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '멜론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름: 김철수\n",
        "전화번호 : 010-1234-1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "re.findall('\\d+', \"문자열입니당.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOrMZsxpqFl6",
        "outputId": "aea6417e-32b1-4a41-e601-7944c164e99c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=\"\"\"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "re.findall(\"\\d+\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeOpA7JDqblT",
        "outputId": "d9bd7a07-9104-4861-e786-051dcf399262"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '1234', '1234', '30']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "re.findall('\\d+', '제 전화번호는 010-8333-2222입니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9vrS76ArP77",
        "outputId": "2efaf03c-372c-4d5a-f21d-8bc9b6cf1491"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '8333', '2222']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름: 가나다\n",
        "ID: 0001\n",
        "\"\"\"\n",
        "\n",
        "re.findall('\\d+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OABi3SyrcSA",
        "outputId": "1b008bdb-3fe7-4985-f8fb-5bbca7d17cbc"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0001']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=\"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "re.sub('[a-zA-Z]', '1', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uqhBZfqhru-e",
        "outputId": "90770e56-902e-4d49-c9a4-e88981240626"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1111111 1111111111 : 1 1111111 1111111111, 11111 11 111111[1] (111111111 111111 1 11111111 1111111111)[2][3] 11, 11 11111111111 11111111 1111111 111 111111 11111111 111111, 1 11111111 11 1111111111 1111 111111 1 111111 1111111.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"100 John    PROF\n",
        "101 James    STUD\n",
        "102 Mac    STUD\"\"\"\n",
        "re.split('\\s+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xX3gnOzsZFp",
        "outputId": "9af3e7de-4356-45f6-d225-163e91568aa9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"100 John    PROF\n",
        "101 James    STUD\n",
        "102 Mac    STUD\"\"\"\n",
        "re.split('\\s+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS9BZDgFsv7Y",
        "outputId": "3fa5ef50-c12b-40dd-b5cf-8779e3873135"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\d+', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF3V4213tUae",
        "outputId": "d4e8776f-b3a0-4f08-b9c8-16938b13ce75"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d23YBnBEtXab",
        "outputId": "87b710a2-29e6-4300-85e3-8ad79e96594a"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub('[A-Z]', '1', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XQQKghG7ta_A",
        "outputId": "bc4087cc-ff9b-4eb1-8bf9-63d0935f17fa"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'100 1ohn    1111\\n101 1ames    1111\\n102 1ac    1111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "letters_only = re.sub('[^a-zA-Z]', ' ', text)\n",
        "letters_only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "469T2xBOthcO",
        "outputId": "e34ec8c5-4486-4bf8-daab-f8dda803fda8"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    John    PROF     James    STUD     Mac    STUD'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"011\n",
        "000\n",
        "000\"\"\"\n",
        "\n",
        "re.sub('[0-9]', ' ', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XNuXeC4Iul0k",
        "outputId": "87892551-85f1-47d3-af28-75e8f2424617"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   \\n   \\n   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num1 = '123 456 7890'\n",
        "\n",
        "pattern1 = '\\d+[-\\s]?\\d+[-\\s]?\\d+'\n",
        "\n",
        "r = re.compile(pattern1)\n",
        "a = r.search(num1)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cw-xYBAu8e4",
        "outputId": "b14d6fd0-bb22-4e8d-c17c-91ba47f183dc"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 12), match='123 456 7890'>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "print(tokenizer.tokenize(\"Don't hesitate to ask questions\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxUvhHO0v817",
        "outputId": "d16f020e-504b-48f4-c86d-7a3a51aff543"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Don't\", 'hesitate', 'to', 'ask', 'questions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kr3RT7jx_0x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}